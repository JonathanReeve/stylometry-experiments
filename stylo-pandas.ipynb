{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the raw text files\n",
    "austenRaw = open('data/austen.txt').read().lower()\n",
    "melvilleRaw = open('data/melville.txt').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeff\\npride an\\n\\n\\nmoby di'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austenRaw[:10] + melvilleRaw[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meltokens = nltk.tokenize.word_tokenize(melvilleRaw)\n",
    "austokens = nltk.tokenize.word_tokenize(austenRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "import string\n",
    "meltokens = [word for word in meltokens if word.isalpha()]\n",
    "austokens = [word for word in austokens if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pieces(text, length, num): \n",
    "    out = [] \n",
    "    for x in range(num): \n",
    "        out.append(text[length*x:length*(x+1)])\n",
    "    return out\n",
    "\n",
    "#mel_pieces = [text1[:1000], text1[1001:2000, text1[2001:3000], text1[3001:4000]]\n",
    "\n",
    "melpieces = pieces(meltokens, 1000, 4)\n",
    "auspieces = pieces(austokens, 1000, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def freqdists(pieceslist): \n",
    "    dists=[]\n",
    "    for piece in pieceslist: \n",
    "        dists.append(nltk.FreqDist(piece).most_common())\n",
    "    return dists\n",
    "\n",
    "meldists = freqdists(melpieces)\n",
    "ausdists = freqdists(auspieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 57),\n",
       " ('and', 33),\n",
       " ('of', 33),\n",
       " ('to', 25),\n",
       " ('in', 18),\n",
       " ('a', 17),\n",
       " ('that', 16),\n",
       " ('whale', 12),\n",
       " ('his', 12),\n",
       " ('is', 10)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meldists[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdf1 = pd.DataFrame(meldists[0], columns=['word', 'mel1'])\n",
    "mdf1 = pd.DataFrame(meldists[0], columns=['word', 'mel1'])\n",
    "mdf1 = pd.DataFrame(meldists[0], columns=['word', 'mel1'])\n",
    "mdf1 = pd.DataFrame(meldists[0], columns=['word', 'mel1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeDataFrame(piece, label):\n",
    "    return pd.DataFrame(piece, columns=['word', label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for idx, val in enumerate(meldists): \n",
    "    dfs.append(makeDataFrame(val, 'mel'+str(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in dfs[1:]: \n",
    "    dfs[0] = pd.merge(dfs[0], df, how='outer', on='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  the\n",
       "1                  and\n",
       "2                   of\n",
       "3                   to\n",
       "4                   in\n",
       "5                    a\n",
       "6                 that\n",
       "7                whale\n",
       "8                  his\n",
       "9                   is\n",
       "10                  or\n",
       "11                 for\n",
       "12                  it\n",
       "13                  by\n",
       "14                  he\n",
       "15                  as\n",
       "16                this\n",
       "17               great\n",
       "18               which\n",
       "19                with\n",
       "20           leviathan\n",
       "21              whales\n",
       "22                  be\n",
       "23                  ye\n",
       "24                 him\n",
       "25                  up\n",
       "26                 had\n",
       "27                take\n",
       "28                 one\n",
       "29                 all\n",
       "             ...      \n",
       "1442       unpublished\n",
       "1443            female\n",
       "1444           extreme\n",
       "1445            mystic\n",
       "1446             short\n",
       "1447    circumambulate\n",
       "1448           forward\n",
       "1449             india\n",
       "1450              seem\n",
       "1451          mutineer\n",
       "1452        reciprocal\n",
       "1453             north\n",
       "1454           brother\n",
       "1455            virtue\n",
       "1456           sabbath\n",
       "1457         biography\n",
       "1458             reefs\n",
       "1459              east\n",
       "1460            pistol\n",
       "1461             storm\n",
       "1462            fields\n",
       "1463          coenties\n",
       "1464          american\n",
       "1465        naturalist\n",
       "1466            arches\n",
       "1467          gateways\n",
       "1468             still\n",
       "1469         waterward\n",
       "1470            yonder\n",
       "1471             isles\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bananas', 'oranges']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
